{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import importlib\n",
    "import Transformer_model\n",
    "\n",
    "importlib.reload(Transformer_model)\n",
    "\n",
    "from Transformer_model import Transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Salut': 0, 'comment': 1, 'ca': 2, 'va': 3, '?': 4, '<START>': 5, '<END>': 6, '<PAD>': 7}\n",
      "{'<START>': 0, 'Hi': 1, 'how': 2, 'are': 3, 'you': 4, '?': 5, '<END>': 6, '<PAD>': 7}\n",
      "['Salut', 'comment', 'ca', 'va', '?']\n",
      "['<START>', 'Hi', 'how', 'are', 'you', '?']\n",
      "input_seq [[0 1 2 3 4]]\n",
      "output_seq [[0 1 2 3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "input_embedding = [[\n",
    "  \"Salut\", \"comment\", \"ca\", \"va\", \"?\"\n",
    "]]\n",
    "\n",
    "\n",
    "output_embedding = [[\n",
    "    \"<START>\", \"Hi\", \"how\", \"are\", \"you\", \"?\"\n",
    "]]\n",
    "\n",
    "def get_vocabulary(sequences):\n",
    "\n",
    "  token_to_info = {}\n",
    "\n",
    "  for sequence in sequences:\n",
    "    for word in sequence:\n",
    "      if word not in token_to_info:\n",
    "        token_to_info[word] = len(token_to_info)\n",
    "  \n",
    "  return token_to_info\n",
    "\n",
    "input_voc = get_vocabulary(input_embedding)\n",
    "output_voc = get_vocabulary(output_embedding)\n",
    "\n",
    "input_voc[\"<START>\"] = len(input_voc)\n",
    "input_voc[\"<END>\"] = len(input_voc)\n",
    "input_voc[\"<PAD>\"] = len(input_voc)\n",
    "\n",
    "output_voc[\"<END>\"] = len(output_voc)\n",
    "output_voc[\"<PAD>\"] = len(output_voc)\n",
    "\n",
    "print(input_voc)\n",
    "print(output_voc)\n",
    "\n",
    "def sequences_to_int(sequences, voc):\n",
    "  for sequence in sequences:\n",
    "    print(sequence)\n",
    "    for s, word in enumerate(sequence):\n",
    "      sequence[s] = voc[word]\n",
    "  return np.array(sequences)\n",
    "\n",
    "input_seq = sequences_to_int(input_embedding, input_voc)\n",
    "output_seq = sequences_to_int(output_embedding, output_voc)\n",
    "\n",
    "print(\"input_seq\", input_seq)\n",
    "print(\"output_seq\", output_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 6, 256), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'decoder__layer_6'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 6, 8), dtype=tf.float32, name=None), name='tf.nn.softmax_3/Softmax:0', description=\"created by layer 'tf.nn.softmax_3'\")\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding__layer_12 (Embedding  (None, 5, 256)      1280        ['input_13[0][0]']               \n",
      " _Layer)                                                                                          \n",
      "                                                                                                  \n",
      " embedding__layer_13 (Embedding  (None, 6, 256)      1536        ['input_14[0][0]']               \n",
      " _Layer)                                                                                          \n",
      "                                                                                                  \n",
      " encoder__layer_6 (Encoder_Laye  (None, 5, 256)      1582086     ['embedding__layer_12[0][0]']    \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " decoder__layer_6 (Decoder_Laye  (None, 6, 256)      2766342     ['embedding__layer_13[0][0]',    \n",
      " r)                                                               'encoder__layer_6[0][0]']       \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 6, 8)         2056        ['decoder__layer_6[0][0]']       \n",
      "                                                                                                  \n",
      " tf.nn.softmax_3 (TFOpLambda)   (None, 6, 8)         0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,353,300\n",
      "Trainable params: 4,347,144\n",
      "Non-trainable params: 6,156\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(coding_block=6, dim=256, nbr_heads=8)\n",
    "output = transformer((input_seq, output_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6, 8), dtype=float32, numpy=\n",
       "array([[[0.1238491 , 0.13050523, 0.13011119, 0.11674609, 0.1299998 ,\n",
       "         0.12398236, 0.12079237, 0.12401381],\n",
       "        [0.11879045, 0.12784123, 0.12040306, 0.12518536, 0.12507288,\n",
       "         0.12815298, 0.12947817, 0.12507589],\n",
       "        [0.12616514, 0.12886994, 0.11869114, 0.12379567, 0.12240306,\n",
       "         0.12505707, 0.1277172 , 0.12730074],\n",
       "        [0.12310728, 0.1352459 , 0.1272503 , 0.1196188 , 0.12049329,\n",
       "         0.12673631, 0.12228886, 0.12525918],\n",
       "        [0.1250689 , 0.13408592, 0.12947951, 0.13067433, 0.1230381 ,\n",
       "         0.12658155, 0.1161561 , 0.11491557],\n",
       "        [0.12397202, 0.12923934, 0.12382116, 0.128963  , 0.12246467,\n",
       "         0.12300641, 0.12083924, 0.12769417]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7af6488317c4eae45cfe2d92ddcd760ac10ac76eee454fa0eead8075769044a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
