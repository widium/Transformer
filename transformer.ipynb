{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 12:01:15.271424: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-02 12:01:15.271449: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input\n",
    "from tensorflow import Tensor\n",
    "from keras import Model\n",
    "from keras.layers import Dense\n",
    "from tensorflow.nn import softmax\n",
    "from compute import create_vector_probability_attention\n",
    "from Embedding import Embedding_Layer\n",
    "from Attention import Attention_Layer\n",
    "from Multi_Head_Attention import Multi_Head_Attention_Layer\n",
    "from keras.layers import Normalization\n",
    "from Encoding import Encoder_Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Salut': 0, 'comment': 1, 'ca': 2, 'va': 3, '?': 4, '<START>': 5, '<END>': 6, '<PAD>': 7}\n",
      "{'<START>': 0, 'Hi': 1, 'how': 2, 'are': 3, 'you': 4, '?': 5, '<END>': 6, '<PAD>': 7}\n",
      "['Salut', 'comment', 'ca', 'va', '?']\n",
      "['<START>', 'Hi', 'how', 'are', 'you', '?']\n",
      "input_seq [[0 1 2 3 4]]\n",
      "output_seq [[0 1 2 3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "input_embedding = [[\n",
    "  \"Salut\", \"comment\", \"ca\", \"va\", \"?\"\n",
    "]]\n",
    "\n",
    "\n",
    "output_embedding = [[\n",
    "    \"<START>\", \"Hi\", \"how\", \"are\", \"you\", \"?\"\n",
    "]]\n",
    "\n",
    "def get_vocabulary(sequences):\n",
    "\n",
    "  token_to_info = {}\n",
    "\n",
    "  for sequence in sequences:\n",
    "    for word in sequence:\n",
    "      if word not in token_to_info:\n",
    "        token_to_info[word] = len(token_to_info)\n",
    "  \n",
    "  return token_to_info\n",
    "\n",
    "input_voc = get_vocabulary(input_embedding)\n",
    "output_voc = get_vocabulary(output_embedding)\n",
    "\n",
    "input_voc[\"<START>\"] = len(input_voc)\n",
    "input_voc[\"<END>\"] = len(input_voc)\n",
    "input_voc[\"<PAD>\"] = len(input_voc)\n",
    "\n",
    "output_voc[\"<END>\"] = len(output_voc)\n",
    "output_voc[\"<PAD>\"] = len(output_voc)\n",
    "\n",
    "print(input_voc)\n",
    "print(output_voc)\n",
    "\n",
    "def sequences_to_int(sequences, voc):\n",
    "  for sequence in sequences:\n",
    "    print(sequence)\n",
    "    for s, word in enumerate(sequence):\n",
    "      sequence[s] = voc[word]\n",
    "  return np.array(sequences)\n",
    "\n",
    "input_seq = sequences_to_int(input_embedding, input_voc)\n",
    "output_seq = sequences_to_int(output_embedding, output_voc)\n",
    "\n",
    "print(\"input_seq\", input_seq)\n",
    "print(\"output_seq\", output_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  Decoding_Layer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, dim : int, nbr_heads : int, mask_size : int,  **kwargs):\n",
    "        self.dim = dim\n",
    "        self.nbr_heads = nbr_heads\n",
    "        self.mask_size = mask_size\n",
    "        super(**kwargs).__init__()\n",
    "       \n",
    "    def build(self, input_shape):\n",
    "        # self.masked_multi_head_attention = Masked_Multi_Head_Attention_Layer(self.dim, self.nbr_heads, self.mask_size)\n",
    "        # self.normalization = Normalization()\n",
    "        # self.dense = Dense(256)\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        encodeur, output_embedding = x\n",
    "        # attention = self.masked_multi_head_attention(x)\n",
    "        # attention_normalize = self.normalization(attention + x)\n",
    "        # dense = self.dense(attention_normalize)\n",
    "        # output = self.normalization(dense + attention_normalize)\n",
    "        \n",
    "        return (x) \n",
    "    \n",
    "class Decoder_Layer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, nb_decoder : int, dim : int, nbr_heads : int, mask_size : int,  **kwargs):\n",
    "        self.nb_decoder = nb_decoder\n",
    "        self.dim = dim\n",
    "        self.nbr_heads = nbr_heads\n",
    "        self.mask_size = mask_size\n",
    "        super(**kwargs).__init__()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.decoder_layer_list = []\n",
    "\n",
    "        for _ in range(self.nb_decoder):\n",
    "            decoder_layer = Decoding_Layer(self.dim, self.nbr_heads, self.mask_size)\n",
    "            self.decoder_layer_list.append(decoder_layer)\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        encoder, output_embedding = x\n",
    "        \n",
    "        decoder_output = output_embedding\n",
    "        \n",
    "        for decoder_layer in self.decoder_layer_list:\n",
    "            decoder_output = decoder_layer((encoder, decoder_output))\n",
    "        return (x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NBR_TOKEN = 5\n",
    "INPUT_SIZE = 5\n",
    "OUTPUT_SIZE = 6\n",
    "\n",
    "def build_Model(coding_block : int, dim : int, nbr_heads : int, mask_size : int):\n",
    "    \n",
    "    input_token = Input(shape=(INPUT_SIZE))\n",
    "    output_token = Input(shape=(OUTPUT_SIZE))\n",
    "    \n",
    "    input_embedding = Embedding_Layer(INPUT_SIZE)(input_token)\n",
    "    output_embedding = Embedding_Layer(OUTPUT_SIZE)(output_token)\n",
    "    \n",
    "    encoder = Encoder_Layer(coding_block, dim, nbr_heads)(input_embedding)\n",
    "    \n",
    "    decoder = Decoder_Layer(coding_block, dim, nbr_heads, mask_size)((encoder, output_embedding))\n",
    "\n",
    "    model = Model([input_token, output_token], decoder)\n",
    "    model.summary()\n",
    "    return (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding__layer_4 (Embedding_  (None, 5, 256)      1280        ['input_5[0][0]']                \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " encoder__layer_2 (Encoder_Laye  (None, 5, 256)      1582086     ['embedding__layer_4[0][0]']     \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " embedding__layer_5 (Embedding_  (None, 6, 256)      1536        ['input_6[0][0]']                \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " decoder__layer_2 (Decoder_Laye  ((None, 5, 256),    0           ['encoder__layer_2[0][0]',       \n",
      " r)                              (None, 6, 256))                  'embedding__layer_5[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,584,902\n",
      "Trainable params: 1,581,824\n",
      "Non-trainable params: 3,078\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_Model(coding_block=6, dim=256, nbr_heads=8, mask_size=6)\n",
    "output = model((input_seq, output_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 256), dtype=float32, numpy=\n",
       "array([[[ 1.4503533 , -0.3028434 ,  0.40352502, ..., -0.77106094,\n",
       "          1.1617829 , -0.6936591 ],\n",
       "        [ 1.246748  ,  0.2138382 ,  0.46494538, ..., -0.9506548 ,\n",
       "          1.1282066 , -0.61845905],\n",
       "        [ 1.498886  ,  0.28181407,  0.37907103, ..., -0.81980187,\n",
       "          0.9780137 , -0.98988265],\n",
       "        [ 0.9374498 ,  0.04110647,  0.517773  , ..., -0.75270104,\n",
       "          1.2630426 , -1.001419  ],\n",
       "        [ 1.3170918 ,  0.19625492,  0.639094  , ..., -0.43390927,\n",
       "          0.8181146 , -0.38335136]]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7af6488317c4eae45cfe2d92ddcd760ac10ac76eee454fa0eead8075769044a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
