# Embedding Layer
## **Learn how to represent words in Input** 
~~~python
Embedding("Number of tokens", "Size of embedding")
~~~
- define** a method `build()` with the class [Embedding](https://keras.io/api/layers/core_layers/embedding/) which takes as argument :
	- an `nbr_token`
	- a `representation` 256
- define a method `call` which takes a sequence of Token as parameter and returns an embedding

# Positional Encoding Layer
soon