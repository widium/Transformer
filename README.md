# Transformer
### **Create Transformer from scratch,  from the paper "Attention is all you need".**

- [1. Understanding Architecture](#understanding-architecture)
- [2. Attention Mecanism](source/Attention)
- [3. Embedding](source/Embedding)
- [4. Positional Encoding](source/Embedding)
- [5. Encoder](source/Encoder)
- [6. Decoder](source/Decoder)

## Understanding Architecture
Transformer use the [Attention Mecanism](source/Attention) for learn to extract features with [Encoder](source/Encoder) and [Decoder](source/Decoder)

![](https://i.imgur.com/dggyZEz.png)
