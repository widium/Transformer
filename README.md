# Transformer
### **Create Transformer from scratch,  from the paper "Attention is all you need".**

- [1. Attention Mecanism](source/Attention)
- [2. Embedding](source/Embedding)
- [3. Encoder](source/Encoder)
- [4. Decoder](source/Decoder)

## Understanding Architecture
Transformer use the [Attention Mecanism](source/Attention) for learn to extract features with [Encoder](source/Encoder) and [Decoder](source/Decoder)

![](https://i.imgur.com/dggyZEz.png)
