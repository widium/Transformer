# Transformer
### **Create Transformer from scratch,  from the paper "Attention is all you need".**

- [1. Understanding Architecture](#understanding-architecture)
- [2. Attention Mecanism](source/Attention)
- [4. Create Mask](source/Mask)
- [2. Embedding](source/Embedding)
- [3. Positional Encoding](source/Embedding)
- [4. Normalize Layer](source/Normalize/)
- [4. Encoder](source/Encoder/Encoder/)
- [5. Decoder](source/Decoder/Decoder/)

## Understanding Architecture
Transformer use the [Attention Mecanism](source/Attention) for learn to extract features with [Encoder](source/Encoder/Encoder/) and [Decoder](source/Decoder/Decoder/)

![](https://i.imgur.com/dggyZEz.png)
